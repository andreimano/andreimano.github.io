---
---

@misc{qian2023probabilistically,
      abbr={ICML23},
      title={Probabilistically Rewired Message-Passing Neural Networks}, 
      author={Chendi Qian and Andrei Manolache and Kareem Ahmed and Zhe Zeng and Guy Van den Broeck and Mathias Niepert and Christopher Morris},
      year={2024},
      month=jan,
      selected={true},
}

@inproceedings{bejan-etal-2023-ad,
    abbr={EMNLP23},
    selected={true},
    title = "{AD}-{NLP}: A Benchmark for Anomaly Detection in Natural Language Processing",
    author = "Bejan, Matei  and
      Manolache, Andrei  and
      Popescu, Marius",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.664",
    doi = "10.18653/v1/2023.emnlp-main.664",
    pages = "10766--10778",
    abstract = "Deep learning models have reignited the interest in Anomaly Detection research in recent years. Methods for Anomaly Detection in text have shown strong empirical results on ad-hoc anomaly setups that are usually made by downsampling some classes of a labeled dataset. This can lead to reproducibility issues and models that are biased toward detecting particular anomalies while failing to recognize them in more sophisticated scenarios. In the present work, we provide a unified benchmark for detecting various types of anomalies, focusing on problems that can be naturally formulated as Anomaly Detection in text, ranging from syntax to stylistics. In this way, we are hoping to facilitate research in Text Anomaly Detection. We also evaluate and analyze two strong shallow baselines, as well as two of the current state-of-the-art neural approaches, providing insights into the knowledge the neural models are learning when performing the anomaly detection task. We provide the code for evaluation, downloading, and preprocessing the dataset at https://github.com/mateibejan1/ad-nlp/.",
}


@inproceedings{qian2023probabilistic,
abbr={ICML23DiffAlmostEverything},
title={Probabilistic Task-Adaptive Graph Rewiring},
author={Chendi Qian and Andrei Manolache and Kareem Ahmed and Zhe Zeng and Guy Van den Broeck and Mathias Niepert and Christopher Morris},
booktitle={ICML 2023 Workshop on Differentiable Almost Everything: Differentiable Relaxations, Algorithms, Operators, and Simulators},
year={2023},
month=jul,
selected={false},
url={https://openreview.net/forum?id=YsHKrMPHE1}
}


@article{ICDMAI4TS,
  abbr={ICDM23AI4TS},

  author={Ioana Pintilie and Andrei Manolache and Florin Brad},

  title={Time Series Anomaly Detection using Diffusion-based Models}, 
  
  booktitle= "ICDM 2023 AI for Time Series Workshop",
  month=dec,
  year      = {2023},
  selected  = {false}
}

@article{DBLP:journals/corr/abs-2112-05125,
  abbr={EMNLP22},
  author    = {Florin Brad and
               Andrei Manolache and
               Elena Burceanu and
               Antonio Barbalau and
               Radu Tudor Ionescu and
               Marius Popescu},
  title     = {Rethinking the Authorship Verification Experimental Setups},

  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  booktitle= "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
  month=dec,
  year      = {2022},
  selected  = {true}
}

@misc{https://doi.org/10.48550/arxiv.2207.03477,
  abbr={NeurIPS22},
  doi = {10.48550/ARXIV.2207.03477},
  
  url = {https://arxiv.org/abs/2207.03477},
  
  author = {Manolache, Andrei and Brad, Florin and Barbalau, Antonio and Ionescu, Radu Tudor and Popescu, Marius},
  booktitle= "Proceedings of the 36th Conference on Neural Information Processing Systems, Datasets and Benchmarks Track",

  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {VeriDark: A Large-Scale Benchmark for Authorship Verification on the Dark Web},
  
  publisher = {NeurIPS},
  month=dec,
  year = {2022},
  
  selected={true}
}

@misc{https://doi.org/10.48550/arxiv.2206.15476,
  abbr={NeurIPS22},
  doi = {10.48550/ARXIV.2206.15476},
  
  url = {https://arxiv.org/abs/2206.15476},
  
  author = {DrÄƒgoi, Marius and Burceanu, Elena and Haller, Emanuela and Manolache, Andrei and Brad, Florin},
  booktitle= "Proceedings of the 36th Conference on Neural Information Processing Systems, Datasets and Benchmarks Track",
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly Detection},
  
  publisher = {NeurIPS},
  month = dec,
  year = {2022},
  
  selected={true}
}

@inproceedings{manolache-etal-2021-date,
    abbr={NAACL21},
    title = "{DATE}: Detecting Anomalies in Text via Self-Supervision of Transformers",
    author = "Manolache, Andrei  and
      Brad, Florin  and
      Burceanu, Elena",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.25",
    doi = "10.18653/v1/2021.naacl-main.25",
    pages = "267--277",
    abstract = "Leveraging deep learning models for Anomaly Detection (AD) has seen widespread use in recent years due to superior performances over traditional methods. Recent deep methods for anomalies in images learn better features of normality in an end-to-end self-supervised setting. These methods train a model to discriminate between different transformations applied to visual data and then use the output to compute an anomaly score. We use this approach for AD in text, by introducing a novel pretext task on text sequences. We learn our DATE model end-to-end, enforcing two independent and complementary self-supervision signals, one at the token-level and one at the sequence-level. Under this new task formulation, we show strong quantitative and qualitative results on the 20Newsgroups and AG News datasets. In the semi-supervised setting, we outperform state-of-the-art results by +13.5{\%} and +6.9{\%}, respectively (AUROC). In the unsupervised configuration, DATE surpasses all other methods even when 10{\%} of its training data is contaminated with outliers (compared with 0{\%} for the others).",
    selected={true}
}

@article{DBLP:journals/corr/abs-2108-09810,
  abbr={arXiv},
  author    = {Nina Miolane and
               Matteo Caorsi and
               Umberto Lupo and
               Marius Guerard and
               Nicolas Guigui and
               Johan Mathe and
               Yann Cabanes and
               Wojciech Reise and
               Thomas Davies and
               Ant{\'{o}}nio Leit{\~{a}}o and
               Somesh Mohapatra and
               Saiteja Utpala and
               Shailja Shailja and
               Gabriele Corso and
               Guoxi Liu and
               Federico Iuricich and
               Andrei Manolache and
               Mihaela Nistor and
               Matei Bejan and
               Armand Mihai Nicolicioiu and
               Bogdan{-}Alexandru Luchian and
               Mihai{-}Sorin Stupariu and
               Florent Michel and
               Khanh Dao Duc and
               Bilal Abdulrahman and
               Maxim Beketov and
               Elodie Maignant and
               Zhiyuan Liu and
               Marek Cern{\'{y}} and
               Martin Bauw and
               Santiago Velasco{-}Forero and
               Jes{\'{u}}s Angulo and
               Yanan Long},
  title     = {{ICLR} 2021 Challenge for Computational Geometry {\&} Topology:
               Design and Results},
  journal   = {CoRR},
  volume    = {abs/2108.09810},
  year      = {2021}
}
